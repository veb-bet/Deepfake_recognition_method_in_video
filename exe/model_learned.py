# -*- coding: utf-8 -*-
"""Model_learned.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K-0DpwuyTBLcC6fEKmYhUQHBcaAS5odG

Установка необходимых библиотек:
pip install tensorflow
pip install keras
pip install opencv-python
pip install scikit-learn
"""

import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout

def load_video(path):
    cap = cv2.VideoCapture(path)
    frames = []
    while(cap.isOpened()):
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, (128, 128))
        frames.append(frame)
    cap.release()
    return frames

def preprocess_data(max_frames):
    X = []
    y = []
    for path in [real_videos_path, deepfake_videos_path]:
        for video_file in os.listdir(path):
            video_path = os.path.join(path, video_file)
            frames = load_video(video_path)
            while len(frames) < max_frames:
                frames.append(np.zeros(frames[0].shape, dtype=np.uint8))
            X.append(frames[:max_frames])
            y.append(0 if path == real_videos_path else 1)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)

max_frames = 100  # Максимальное количество кадров для преобразования

real_videos_path = "/content/R"
deepfake_videos_path = "/content/Deep"

X_train, X_test, y_train, y_test = preprocess_data(max_frames)

model = Sequential()
model.add(Conv3D(16, kernel_size=(3, 3, 3), activation='relu', input_shape=X_train.shape[1:]))
model.add(MaxPooling3D(pool_size=(2, 2, 2)))
model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu'))
model.add(MaxPooling3D(pool_size=(2, 2, 2)))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

model.save('model.h5')

# Сохранение модели как JSON
model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)

"""test1 - r
test2 - d
test3 - r
test4 - d
test5 - d
test6 - r

"""

test_video_path = "test6.mp4"  # Путь к файлу с тестовым видео
test_frames = load_video(test_video_path)  # Загрузка и предобработка кадров
while len(test_frames) < max_frames:
    test_frames.append(np.zeros(test_frames[0].shape, dtype=np.uint8))
test_frames = np.array(test_frames[:max_frames])  # Преобразование к массиву кадров

prediction = model.predict(np.array([test_frames]))  # Предсказание
print(prediction[0])
if prediction[0] < 0.3:
    result = "Real Video"
else:
    result = "Deepfake Video"

print("The video is:", result)